* Test Cases
** Unit Tests
  Unit tests done at the function level, not the task level.
  1. Tests for existence of resource files.
  2. Tests for when resource files are well formed.
  3. Tests for when resource files are NOT well formed:
     - file contains leading newline/spaces
     - file is empty
     - file does not contain name and/or version
  4. Test for when both feature flag files are the same
  5. Test for when both feature flag files are NOT the same:
     - one is different
     - both are different
  6. Test for when one feature flag file exists and the other one was deleted
  7. Test for when both feature flag files were deleted
  8. Test when current name/version is the FIRST entry in release info CSV -> no previous version, so can't lookup FF.csv from previous ref -> output meaningful message
  9. Test when current name/version is the LAST entry in release info CSV -> there is no next version, so updating project name/version should fail with meaningful message

** Integration Tests     
  Integration tests at the function level, not the task level. This may be done by mocking the GitHub server so that the tests don't fail if GitHub were to go down. One downside of mocking in this case would be if the endpoints were to ever change. This could be dealt with by an API endpoint translation service or a proxy service by something such as Confluent (see https://github.com/confluentinc/mox) that will proxy endpoints that work, and mock endpoints that do NOT.
  1. Tests for Git operations:
     - test that remote branch exists (name according to release name and release version) -> if not throw exception with meaningful message
     - test that response code is valid when sending GitHub API request -> if not throw exception with meaningful message
     - test that "FF.csv" exists when querying the previous version's branch -> if not throw exception with meaningful message
     - test that when creating branch, the branch is actually created on GitHub.

** E2E Tests       
  End to end tests at the task level, e.g. by calling "gradle <task name>" and examining output or by mocking Gradle project. Mocking end to end tests using Gradle can be done using Gradle's TestKit (https://docs.gradle.org/current/userguide/test_kit.html).
  1. Test that the remote branch is created when running the "cutBranch" task.
  2. Test that the contents of "FF_diff.csv" are correct when running the "generateFFDiff" task.
  3. Test that "release.plist" is correctly updated after "updateReleaseVersion" task is run.
  2. Test that all three tasks can be run together: e.g. "gradle codeFreeze" runs tasks in the following order: cutBranch -> generateFFDiff -> updateReleaseVersion.

** Performance Tests
  These can be done to monitor CPU usage, memory usage, etc. In Gradle, it's possible to register event hooks before, during, and after each task. This can be useful to register a base line for before the task runs, and then after the task runs to compare memory and CPU usage.
  
